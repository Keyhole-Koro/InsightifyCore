// Code generated by protoc-gen-connect-go. DO NOT EDIT.
//
// Source: insightify/v1/llm_chat.proto

package insightifyv1connect

import (
	connect "connectrpc.com/connect"
	context "context"
	errors "errors"
	v1 "insightify/gen/go/insightify/v1"
	http "net/http"
	strings "strings"
)

// This is a compile-time assertion to ensure that this generated file and the connect package are
// compatible. If you get a compiler error that this constant is not defined, this code was
// generated with a version of connect newer than the one compiled into your binary. You can fix the
// problem by either regenerating this code with an older version of connect or updating the connect
// version compiled into your binary.
const _ = connect.IsAtLeastVersion1_13_0

const (
	// LlmChatServiceName is the fully-qualified name of the LlmChatService service.
	LlmChatServiceName = "insightify.v1.LlmChatService"
)

// These constants are the fully-qualified names of the RPCs defined in this package. They're
// exposed at runtime as Spec.Procedure and as the final two segments of the HTTP route.
//
// Note that these are different from the fully-qualified method names used by
// google.golang.org/protobuf/reflect/protoreflect. To convert from these constants to
// reflection-formatted method names, remove the leading slash and convert the remaining slash to a
// period.
const (
	// LlmChatServiceSendMessageProcedure is the fully-qualified name of the LlmChatService's
	// SendMessage RPC.
	LlmChatServiceSendMessageProcedure = "/insightify.v1.LlmChatService/SendMessage"
)

// LlmChatServiceClient is a client for the insightify.v1.LlmChatService service.
type LlmChatServiceClient interface {
	// Send user follow-up input to a waiting interactive run.
	SendMessage(context.Context, *connect.Request[v1.SendMessageRequest]) (*connect.Response[v1.SendMessageResponse], error)
}

// NewLlmChatServiceClient constructs a client for the insightify.v1.LlmChatService service. By
// default, it uses the Connect protocol with the binary Protobuf Codec, asks for gzipped responses,
// and sends uncompressed requests. To use the gRPC or gRPC-Web protocols, supply the
// connect.WithGRPC() or connect.WithGRPCWeb() options.
//
// The URL supplied here should be the base URL for the Connect or gRPC server (for example,
// http://api.acme.com or https://acme.com/grpc).
func NewLlmChatServiceClient(httpClient connect.HTTPClient, baseURL string, opts ...connect.ClientOption) LlmChatServiceClient {
	baseURL = strings.TrimRight(baseURL, "/")
	llmChatServiceMethods := v1.File_insightify_v1_llm_chat_proto.Services().ByName("LlmChatService").Methods()
	return &llmChatServiceClient{
		sendMessage: connect.NewClient[v1.SendMessageRequest, v1.SendMessageResponse](
			httpClient,
			baseURL+LlmChatServiceSendMessageProcedure,
			connect.WithSchema(llmChatServiceMethods.ByName("SendMessage")),
			connect.WithClientOptions(opts...),
		),
	}
}

// llmChatServiceClient implements LlmChatServiceClient.
type llmChatServiceClient struct {
	sendMessage *connect.Client[v1.SendMessageRequest, v1.SendMessageResponse]
}

// SendMessage calls insightify.v1.LlmChatService.SendMessage.
func (c *llmChatServiceClient) SendMessage(ctx context.Context, req *connect.Request[v1.SendMessageRequest]) (*connect.Response[v1.SendMessageResponse], error) {
	return c.sendMessage.CallUnary(ctx, req)
}

// LlmChatServiceHandler is an implementation of the insightify.v1.LlmChatService service.
type LlmChatServiceHandler interface {
	// Send user follow-up input to a waiting interactive run.
	SendMessage(context.Context, *connect.Request[v1.SendMessageRequest]) (*connect.Response[v1.SendMessageResponse], error)
}

// NewLlmChatServiceHandler builds an HTTP handler from the service implementation. It returns the
// path on which to mount the handler and the handler itself.
//
// By default, handlers support the Connect, gRPC, and gRPC-Web protocols with the binary Protobuf
// and JSON codecs. They also support gzip compression.
func NewLlmChatServiceHandler(svc LlmChatServiceHandler, opts ...connect.HandlerOption) (string, http.Handler) {
	llmChatServiceMethods := v1.File_insightify_v1_llm_chat_proto.Services().ByName("LlmChatService").Methods()
	llmChatServiceSendMessageHandler := connect.NewUnaryHandler(
		LlmChatServiceSendMessageProcedure,
		svc.SendMessage,
		connect.WithSchema(llmChatServiceMethods.ByName("SendMessage")),
		connect.WithHandlerOptions(opts...),
	)
	return "/insightify.v1.LlmChatService/", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		switch r.URL.Path {
		case LlmChatServiceSendMessageProcedure:
			llmChatServiceSendMessageHandler.ServeHTTP(w, r)
		default:
			http.NotFound(w, r)
		}
	})
}

// UnimplementedLlmChatServiceHandler returns CodeUnimplemented from all methods.
type UnimplementedLlmChatServiceHandler struct{}

func (UnimplementedLlmChatServiceHandler) SendMessage(context.Context, *connect.Request[v1.SendMessageRequest]) (*connect.Response[v1.SendMessageResponse], error) {
	return nil, connect.NewError(connect.CodeUnimplemented, errors.New("insightify.v1.LlmChatService.SendMessage is not implemented"))
}
